{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M12 Seminar: Economic and Social Problems: Insights from Big Data.\n",
    "# Term Paper. \n",
    "# Replication file â„–4 - out-of-sample analysis (prediction) + XGBoost extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load US time series data\n",
    "### Files can be found [here](https://github.com/social-connectedness-index/example-scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53363, 91)\n"
     ]
    }
   ],
   "source": [
    "ts_df = pd.read_csv('covid19_exploration/_intermediate/time_series_regress_dat.csv', encoding='cp1251')\n",
    "ts_df['date'] = pd.to_datetime(ts_df['date'])\n",
    "print(ts_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3139\n"
     ]
    }
   ],
   "source": [
    "# unique counties\n",
    "counties = pd.unique(ts_df['county_fips'])\n",
    "print(len(counties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "target = ['log_chg_cases_10k']\n",
    "# baseline features\n",
    "baseline_cases = ['log_l1_chg_dwc_10k', \n",
    "                  'log_l2_chg_dwc_10k', \n",
    "                  'log_l1_chg_cases_10k',\n",
    "                  'log_l2_chg_cases_10k',\n",
    "                  'med_hhinc2016_10k', \n",
    "                  'popdensity2010_10k']\n",
    "# lex features\n",
    "lex_cases_vars = ['log_l1_chg_lwc_10k', 'log_l2_chg_lwc_10k']\n",
    "# sci features\n",
    "sci_cases_vars = ['log_l1_chg_swc_10k', 'log_l2_chg_swc_10k']\n",
    "# goggle features\n",
    "google_vars = ['l1_pchg_gogl_fever', 'l1_pchg_gogl_cough', 'l1_pchg_gogl_fatigue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that performs out-of-sample forecast (random forest)\n",
    "# returns RMSE on train and test (out-of-sample) data\n",
    "def fit_random_forest(x_train, y_train, x_test, y_test):\n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_depth=3, random_state=777, n_jobs=-1)\n",
    "    rfr.fit(x_train, y_train)\n",
    "    rfr_test_pred = rfr.predict(x_test)\n",
    "    rfr_train_pred = rfr.predict(x_train)\n",
    "    train_loss = mean_squared_error(y_true=y_train, y_pred=rfr_train_pred) ** 0.5\n",
    "    test_loss = mean_squared_error(y_true=y_test, y_pred=rfr_test_pred) ** 0.5\n",
    "    return train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that performs out-of-sample forecast (gradient boosting)\n",
    "# returns RMSE on train and test (out-of-sample) data\n",
    "def fit_xgboost(x_train, y_train, x_test, y_test, max_depth=3):\n",
    "    xgb = xgboost.XGBRegressor(n_estimators=500, max_depth=max_depth, random_state=777, n_jobs=-1)\n",
    "    xgb.fit(x_train, y_train)\n",
    "    xgb_test_pred = xgb.predict(x_test)\n",
    "    xgb_train_pred = xgb.predict(x_train)\n",
    "    train_loss = mean_squared_error(y_true=y_train, y_pred=xgb_train_pred) ** 0.5\n",
    "    test_loss = mean_squared_error(y_true=y_test, y_pred=xgb_test_pred) ** 0.5\n",
    "    return train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supplementary function for model training\n",
    "def get_train_test_data(train, test, colnames):\n",
    "    x_train = train[colnames + target].dropna()\n",
    "    y_train = x_train[target]\n",
    "    x_train = x_train.drop(target, axis=1)\n",
    "    x_test = test[colnames].fillna(0)\n",
    "    y_test = test[target]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3417c12a4746258e1c163256ec24bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline train DF shape : (3139, 6)\n",
      "Baseline+SCI train DF shape : (3139, 8)\n",
      "Baseline+LEX+Google train DF shape : (1976, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (1976, 13)\n",
      "\n",
      "Baseline train DF shape : (6278, 6)\n",
      "Baseline+SCI train DF shape : (6278, 8)\n",
      "Baseline+LEX+Google train DF shape : (3952, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (3952, 13)\n",
      "\n",
      "Baseline train DF shape : (9417, 6)\n",
      "Baseline+SCI train DF shape : (9417, 8)\n",
      "Baseline+LEX+Google train DF shape : (5928, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (5928, 13)\n",
      "\n",
      "Baseline train DF shape : (12556, 6)\n",
      "Baseline+SCI train DF shape : (12556, 8)\n",
      "Baseline+LEX+Google train DF shape : (7904, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (7904, 13)\n",
      "\n",
      "Baseline train DF shape : (15695, 6)\n",
      "Baseline+SCI train DF shape : (15695, 8)\n",
      "Baseline+LEX+Google train DF shape : (9880, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (9880, 13)\n",
      "\n",
      "Baseline train DF shape : (18834, 6)\n",
      "Baseline+SCI train DF shape : (18834, 8)\n",
      "Baseline+LEX+Google train DF shape : (11856, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (11856, 13)\n",
      "\n",
      "Baseline train DF shape : (21973, 6)\n",
      "Baseline+SCI train DF shape : (21973, 8)\n",
      "Baseline+LEX+Google train DF shape : (13832, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (13832, 13)\n",
      "\n",
      "Baseline train DF shape : (25112, 6)\n",
      "Baseline+SCI train DF shape : (25112, 8)\n",
      "Baseline+LEX+Google train DF shape : (15808, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (15808, 13)\n",
      "\n",
      "Baseline train DF shape : (28251, 6)\n",
      "Baseline+SCI train DF shape : (28251, 8)\n",
      "Baseline+LEX+Google train DF shape : (17784, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (17784, 13)\n",
      "\n",
      "Baseline train DF shape : (31390, 6)\n",
      "Baseline+SCI train DF shape : (31390, 8)\n",
      "Baseline+LEX+Google train DF shape : (19760, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (19760, 13)\n",
      "\n",
      "Baseline train DF shape : (34529, 6)\n",
      "Baseline+SCI train DF shape : (34529, 8)\n",
      "Baseline+LEX+Google train DF shape : (21736, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (21736, 13)\n",
      "\n",
      "Baseline train DF shape : (37668, 6)\n",
      "Baseline+SCI train DF shape : (37668, 8)\n",
      "Baseline+LEX+Google train DF shape : (23712, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (23712, 13)\n",
      "\n",
      "Baseline train DF shape : (40807, 6)\n",
      "Baseline+SCI train DF shape : (40807, 8)\n",
      "Baseline+LEX+Google train DF shape : (25688, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (25688, 13)\n",
      "\n",
      "Baseline train DF shape : (43946, 6)\n",
      "Baseline+SCI train DF shape : (43946, 8)\n",
      "Baseline+LEX+Google train DF shape : (27664, 11)\n",
      "Baseline+LEX+Google+SCI train DF shape : (27664, 13)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iterative out-of-sample forecasting (random forest and gradient boosting)\n",
    "rfr_baseline_losses = []\n",
    "rfr_baseline_sci_losses = []\n",
    "\n",
    "xgb_baseline_losses = []\n",
    "xgb_baseline_sci_losses = []\n",
    "\n",
    "rfr_baseline_lex_google_losses = []\n",
    "rfr_baseline_lex_google_sci_losses = []\n",
    "\n",
    "xgb_baseline_lex_google_losses = []\n",
    "xgb_baseline_lex_google_sci_losses = []\n",
    "\n",
    "for week_num in tqdm(range(17, 45, 2)):\n",
    "    train = ts_df.loc[ts_df['week_num'] < week_num]\n",
    "    test = ts_df.loc[ts_df['week_num'] == week_num]\n",
    "    \n",
    "    x_train_baseline, y_train_baseline, x_test_baseline, y_test_baseline = get_train_test_data(train, test, baseline_cases)\n",
    "    print(f'Baseline train DF shape : {x_train_baseline.shape}')\n",
    "    \n",
    "    x_train_baseline_sci, y_train_baseline_sci, x_test_baseline_sci, y_test_baseline_sci = get_train_test_data(train, test, baseline_cases + sci_cases_vars)\n",
    "    print(f'Baseline+SCI train DF shape : {x_train_baseline_sci.shape}')\n",
    "    \n",
    "    x_train_baseline_lex_google, y_train_baseline_lex_google, x_test_baseline_lex_google, y_test_baseline_lex_google = get_train_test_data(train, test, baseline_cases + lex_cases_vars + google_vars)\n",
    "    print(f'Baseline+LEX+Google train DF shape : {x_train_baseline_lex_google.shape}')\n",
    "    \n",
    "    x_train_baseline_lex_google_sci, y_train_baseline_lex_google_sci, x_test_baseline_lex_google_sci, y_test_baseline_lex_google_sci = get_train_test_data(train, test, baseline_cases + lex_cases_vars + google_vars + sci_cases_vars)\n",
    "    print(f'Baseline+LEX+Google+SCI train DF shape : {x_train_baseline_lex_google_sci.shape}')\n",
    "    \n",
    "    \n",
    "    # baseline random forest\n",
    "    rfr_train_loss, rfr_test_loss = fit_random_forest(x_train=x_train_baseline, \n",
    "                                                      y_train=y_train_baseline, \n",
    "                                                      x_test=x_test_baseline, \n",
    "                                                      y_test=y_test_baseline)\n",
    "    \n",
    "    rfr_baseline_losses.append([rfr_train_loss, rfr_test_loss])\n",
    "    \n",
    "    # baseline xgboost\n",
    "    xgb_train_loss, xgb_test_loss = fit_xgboost(x_train=x_train_baseline, \n",
    "                                                y_train=y_train_baseline, \n",
    "                                                x_test=x_test_baseline, \n",
    "                                                y_test=y_test_baseline)\n",
    "    \n",
    "    xgb_baseline_losses.append([xgb_train_loss, xgb_test_loss])\n",
    "    \n",
    "    # baseline + sci random forest\n",
    "    rfr_train_loss, rfr_test_loss = fit_random_forest(x_train=x_train_baseline_sci, \n",
    "                                                      y_train=y_train_baseline_sci, \n",
    "                                                      x_test=x_test_baseline_sci, \n",
    "                                                      y_test=y_test_baseline_sci)\n",
    "    \n",
    "    rfr_baseline_sci_losses.append([rfr_train_loss, rfr_test_loss])\n",
    "    \n",
    "    # baseline + sci xgboost\n",
    "    xgb_train_loss, xgb_test_loss = fit_xgboost(x_train=x_train_baseline_sci, \n",
    "                                                      y_train=y_train_baseline_sci, \n",
    "                                                      x_test=x_test_baseline_sci, \n",
    "                                                      y_test=y_test_baseline_sci)\n",
    "    \n",
    "    xgb_baseline_sci_losses.append([xgb_train_loss, xgb_test_loss])\n",
    "    \n",
    "    # baseline + LEX + Google random forest\n",
    "    rfr_train_loss, rfr_test_loss = fit_random_forest(x_train=x_train_baseline_lex_google, \n",
    "                                                      y_train=y_train_baseline_lex_google, \n",
    "                                                      x_test=x_test_baseline_lex_google, \n",
    "                                                      y_test=y_test_baseline_lex_google)\n",
    "    \n",
    "    rfr_baseline_lex_google_losses.append([rfr_train_loss, rfr_test_loss])\n",
    "    \n",
    "    # baseline + LEX + Google xgboost\n",
    "    xgb_train_loss, xgb_test_loss = fit_xgboost(x_train=x_train_baseline_lex_google, \n",
    "                                                      y_train=y_train_baseline_lex_google, \n",
    "                                                      x_test=x_test_baseline_lex_google, \n",
    "                                                      y_test=y_test_baseline_lex_google)\n",
    "    \n",
    "    xgb_baseline_lex_google_losses.append([xgb_train_loss, xgb_test_loss])\n",
    "    \n",
    "    # baseline + LEX + Google + sci random forest\n",
    "    rfr_train_loss, rfr_test_loss = fit_random_forest(x_train=x_train_baseline_lex_google_sci, \n",
    "                                                      y_train=y_train_baseline_lex_google_sci, \n",
    "                                                      x_test=x_test_baseline_lex_google_sci, \n",
    "                                                      y_test=y_test_baseline_lex_google_sci)\n",
    "    \n",
    "    rfr_baseline_lex_google_sci_losses.append([rfr_train_loss, rfr_test_loss])\n",
    "    \n",
    "    # baseline + LEX + Google + sci xgboost\n",
    "    xgb_train_loss, xgb_test_loss = fit_xgboost(x_train=x_train_baseline_lex_google_sci, \n",
    "                                                      y_train=y_train_baseline_lex_google_sci, \n",
    "                                                      x_test=x_test_baseline_lex_google_sci, \n",
    "                                                      y_test=y_test_baseline_lex_google_sci)\n",
    "    \n",
    "    xgb_baseline_lex_google_sci_losses.append([xgb_train_loss, xgb_test_loss])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer train and test RMSEs into numpy.ndarray format\n",
    "rfr_baseline_losses = np.array(rfr_baseline_losses)\n",
    "rfr_baseline_sci_losses = np.array(rfr_baseline_sci_losses)\n",
    "\n",
    "xgb_baseline_losses = np.array(xgb_baseline_losses)\n",
    "xgb_baseline_sci_losses = np.array(xgb_baseline_sci_losses)\n",
    "\n",
    "rfr_baseline_lex_google_losses = np.array(rfr_baseline_lex_google_losses)\n",
    "rfr_baseline_lex_google_sci_losses = np.array(rfr_baseline_lex_google_sci_losses)\n",
    "\n",
    "xgb_baseline_lex_google_losses = np.array(xgb_baseline_lex_google_losses)\n",
    "xgb_baseline_lex_google_sci_losses = np.array(xgb_baseline_lex_google_sci_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct DataFrame with RMSEs of all models\n",
    "replication_df = pd.DataFrame()\n",
    "\n",
    "replication_df['rfr_baseline_losses_train'] = rfr_baseline_losses[:, 0]\n",
    "replication_df['rfr_baseline_losses_test'] = rfr_baseline_losses[:, 1]\n",
    "\n",
    "replication_df['rfr_baseline_sci_losses_train'] = rfr_baseline_sci_losses[:, 0]\n",
    "replication_df['rfr_baseline_sci_losses_test'] = rfr_baseline_sci_losses[:, 1]\n",
    "\n",
    "replication_df['xgb_baseline_losses_train'] = xgb_baseline_losses[:, 0]\n",
    "replication_df['xgb_baseline_losses_test'] = xgb_baseline_losses[:, 1]\n",
    "\n",
    "replication_df['xgb_baseline_sci_losses_train'] = xgb_baseline_sci_losses[:, 0]\n",
    "replication_df['xgb_baseline_sci_losses_test'] = xgb_baseline_sci_losses[:, 1]\n",
    "\n",
    "replication_df['rfr_baseline_lex_google_losses_train'] = rfr_baseline_lex_google_losses[:, 0]\n",
    "replication_df['rfr_baseline_lex_google_losses_test'] = rfr_baseline_lex_google_losses[:, 1]\n",
    "\n",
    "replication_df['rfr_baseline_lex_google_sci_losses_train'] = rfr_baseline_lex_google_sci_losses[:, 0]\n",
    "replication_df['rfr_baseline_lex_google_sci_losses_test'] = rfr_baseline_lex_google_sci_losses[:, 1]\n",
    "\n",
    "replication_df['xgb_baseline_lex_google_losses_train'] = xgb_baseline_lex_google_losses[:, 0]\n",
    "replication_df['xgb_baseline_lex_google_losses_test'] = xgb_baseline_lex_google_losses[:, 1]\n",
    "\n",
    "replication_df['xgb_baseline_lex_google_sci_losses_train'] = xgb_baseline_lex_google_sci_losses[:, 0]\n",
    "replication_df['xgb_baseline_lex_google_sci_losses_test'] = xgb_baseline_lex_google_sci_losses[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save DataFrame in .csv format\n",
    "replication_df.to_csv('replication_oos_rmse_rf_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rfr_baseline_losses_train</th>\n",
       "      <th>rfr_baseline_losses_test</th>\n",
       "      <th>rfr_baseline_sci_losses_train</th>\n",
       "      <th>rfr_baseline_sci_losses_test</th>\n",
       "      <th>xgb_baseline_losses_train</th>\n",
       "      <th>xgb_baseline_losses_test</th>\n",
       "      <th>xgb_baseline_sci_losses_train</th>\n",
       "      <th>xgb_baseline_sci_losses_test</th>\n",
       "      <th>rfr_baseline_lex_google_losses_train</th>\n",
       "      <th>rfr_baseline_lex_google_losses_test</th>\n",
       "      <th>rfr_baseline_lex_google_sci_losses_train</th>\n",
       "      <th>rfr_baseline_lex_google_sci_losses_test</th>\n",
       "      <th>xgb_baseline_lex_google_losses_train</th>\n",
       "      <th>xgb_baseline_lex_google_losses_test</th>\n",
       "      <th>xgb_baseline_lex_google_sci_losses_train</th>\n",
       "      <th>xgb_baseline_lex_google_sci_losses_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.669652</td>\n",
       "      <td>1.124411</td>\n",
       "      <td>0.651928</td>\n",
       "      <td>1.330899</td>\n",
       "      <td>0.298636</td>\n",
       "      <td>1.701912</td>\n",
       "      <td>0.264178</td>\n",
       "      <td>1.620042</td>\n",
       "      <td>0.548788</td>\n",
       "      <td>1.220528</td>\n",
       "      <td>0.543343</td>\n",
       "      <td>1.326225</td>\n",
       "      <td>0.124243</td>\n",
       "      <td>1.158518</td>\n",
       "      <td>0.106177</td>\n",
       "      <td>1.282564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.755244</td>\n",
       "      <td>0.775609</td>\n",
       "      <td>0.754838</td>\n",
       "      <td>0.775406</td>\n",
       "      <td>0.440828</td>\n",
       "      <td>0.983207</td>\n",
       "      <td>0.404515</td>\n",
       "      <td>0.961906</td>\n",
       "      <td>0.662272</td>\n",
       "      <td>0.865908</td>\n",
       "      <td>0.662111</td>\n",
       "      <td>0.849453</td>\n",
       "      <td>0.249522</td>\n",
       "      <td>1.121128</td>\n",
       "      <td>0.237589</td>\n",
       "      <td>1.207949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.762738</td>\n",
       "      <td>0.741119</td>\n",
       "      <td>0.762508</td>\n",
       "      <td>0.741030</td>\n",
       "      <td>0.507057</td>\n",
       "      <td>0.830562</td>\n",
       "      <td>0.477784</td>\n",
       "      <td>0.775607</td>\n",
       "      <td>0.666381</td>\n",
       "      <td>0.829693</td>\n",
       "      <td>0.665967</td>\n",
       "      <td>0.805936</td>\n",
       "      <td>0.328833</td>\n",
       "      <td>1.025142</td>\n",
       "      <td>0.310682</td>\n",
       "      <td>1.156474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.757707</td>\n",
       "      <td>0.723681</td>\n",
       "      <td>0.757696</td>\n",
       "      <td>0.723586</td>\n",
       "      <td>0.540714</td>\n",
       "      <td>0.737487</td>\n",
       "      <td>0.513552</td>\n",
       "      <td>0.715478</td>\n",
       "      <td>0.657579</td>\n",
       "      <td>0.764084</td>\n",
       "      <td>0.657157</td>\n",
       "      <td>0.756091</td>\n",
       "      <td>0.370802</td>\n",
       "      <td>0.958089</td>\n",
       "      <td>0.363219</td>\n",
       "      <td>1.172175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.753182</td>\n",
       "      <td>0.809167</td>\n",
       "      <td>0.752931</td>\n",
       "      <td>0.807932</td>\n",
       "      <td>0.562597</td>\n",
       "      <td>0.817999</td>\n",
       "      <td>0.536566</td>\n",
       "      <td>0.799842</td>\n",
       "      <td>0.653659</td>\n",
       "      <td>0.831459</td>\n",
       "      <td>0.653390</td>\n",
       "      <td>0.823574</td>\n",
       "      <td>0.398549</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.385329</td>\n",
       "      <td>0.932373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.764238</td>\n",
       "      <td>0.869110</td>\n",
       "      <td>0.762991</td>\n",
       "      <td>0.854253</td>\n",
       "      <td>0.592883</td>\n",
       "      <td>0.881255</td>\n",
       "      <td>0.566314</td>\n",
       "      <td>0.869327</td>\n",
       "      <td>0.663504</td>\n",
       "      <td>0.843810</td>\n",
       "      <td>0.663394</td>\n",
       "      <td>0.845505</td>\n",
       "      <td>0.427720</td>\n",
       "      <td>0.877050</td>\n",
       "      <td>0.417948</td>\n",
       "      <td>0.859528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.780744</td>\n",
       "      <td>0.881134</td>\n",
       "      <td>0.774764</td>\n",
       "      <td>0.861464</td>\n",
       "      <td>0.616987</td>\n",
       "      <td>0.893641</td>\n",
       "      <td>0.591017</td>\n",
       "      <td>0.922350</td>\n",
       "      <td>0.669174</td>\n",
       "      <td>0.821221</td>\n",
       "      <td>0.668374</td>\n",
       "      <td>0.820134</td>\n",
       "      <td>0.438885</td>\n",
       "      <td>0.903794</td>\n",
       "      <td>0.430292</td>\n",
       "      <td>0.822174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.788833</td>\n",
       "      <td>0.694712</td>\n",
       "      <td>0.778617</td>\n",
       "      <td>0.675934</td>\n",
       "      <td>0.622944</td>\n",
       "      <td>0.810184</td>\n",
       "      <td>0.599696</td>\n",
       "      <td>0.829277</td>\n",
       "      <td>0.664334</td>\n",
       "      <td>0.709299</td>\n",
       "      <td>0.663530</td>\n",
       "      <td>0.698256</td>\n",
       "      <td>0.442985</td>\n",
       "      <td>0.837649</td>\n",
       "      <td>0.435387</td>\n",
       "      <td>0.851547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.779220</td>\n",
       "      <td>0.711245</td>\n",
       "      <td>0.770295</td>\n",
       "      <td>0.722962</td>\n",
       "      <td>0.627419</td>\n",
       "      <td>0.827886</td>\n",
       "      <td>0.604393</td>\n",
       "      <td>0.806893</td>\n",
       "      <td>0.650919</td>\n",
       "      <td>0.719212</td>\n",
       "      <td>0.650074</td>\n",
       "      <td>0.735772</td>\n",
       "      <td>0.445284</td>\n",
       "      <td>1.025254</td>\n",
       "      <td>0.439898</td>\n",
       "      <td>1.039725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.774038</td>\n",
       "      <td>0.760590</td>\n",
       "      <td>0.765941</td>\n",
       "      <td>0.758032</td>\n",
       "      <td>0.627335</td>\n",
       "      <td>0.767380</td>\n",
       "      <td>0.606709</td>\n",
       "      <td>0.760211</td>\n",
       "      <td>0.637234</td>\n",
       "      <td>0.769444</td>\n",
       "      <td>0.637021</td>\n",
       "      <td>0.770078</td>\n",
       "      <td>0.443288</td>\n",
       "      <td>0.870846</td>\n",
       "      <td>0.439217</td>\n",
       "      <td>0.867469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.773160</td>\n",
       "      <td>0.729462</td>\n",
       "      <td>0.765970</td>\n",
       "      <td>0.723871</td>\n",
       "      <td>0.633010</td>\n",
       "      <td>0.718728</td>\n",
       "      <td>0.612339</td>\n",
       "      <td>0.708564</td>\n",
       "      <td>0.626943</td>\n",
       "      <td>0.733662</td>\n",
       "      <td>0.626888</td>\n",
       "      <td>0.733561</td>\n",
       "      <td>0.445028</td>\n",
       "      <td>1.006565</td>\n",
       "      <td>0.438914</td>\n",
       "      <td>0.832521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.770534</td>\n",
       "      <td>0.771915</td>\n",
       "      <td>0.763163</td>\n",
       "      <td>0.750645</td>\n",
       "      <td>0.637305</td>\n",
       "      <td>0.760866</td>\n",
       "      <td>0.616239</td>\n",
       "      <td>0.728712</td>\n",
       "      <td>0.619546</td>\n",
       "      <td>0.760020</td>\n",
       "      <td>0.619527</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.447270</td>\n",
       "      <td>1.016009</td>\n",
       "      <td>0.442675</td>\n",
       "      <td>0.993953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.768857</td>\n",
       "      <td>0.722765</td>\n",
       "      <td>0.760381</td>\n",
       "      <td>0.706813</td>\n",
       "      <td>0.640751</td>\n",
       "      <td>0.697524</td>\n",
       "      <td>0.620622</td>\n",
       "      <td>0.694678</td>\n",
       "      <td>0.613457</td>\n",
       "      <td>0.717703</td>\n",
       "      <td>0.613438</td>\n",
       "      <td>0.716925</td>\n",
       "      <td>0.451881</td>\n",
       "      <td>1.007809</td>\n",
       "      <td>0.444940</td>\n",
       "      <td>0.796302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.765514</td>\n",
       "      <td>0.742057</td>\n",
       "      <td>0.756869</td>\n",
       "      <td>0.728658</td>\n",
       "      <td>0.638602</td>\n",
       "      <td>0.677788</td>\n",
       "      <td>0.621636</td>\n",
       "      <td>0.687273</td>\n",
       "      <td>0.608019</td>\n",
       "      <td>0.732488</td>\n",
       "      <td>0.608014</td>\n",
       "      <td>0.732266</td>\n",
       "      <td>0.450587</td>\n",
       "      <td>0.971356</td>\n",
       "      <td>0.444691</td>\n",
       "      <td>1.031364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rfr_baseline_losses_train  rfr_baseline_losses_test  \\\n",
       "0                    0.669652                  1.124411   \n",
       "1                    0.755244                  0.775609   \n",
       "2                    0.762738                  0.741119   \n",
       "3                    0.757707                  0.723681   \n",
       "4                    0.753182                  0.809167   \n",
       "5                    0.764238                  0.869110   \n",
       "6                    0.780744                  0.881134   \n",
       "7                    0.788833                  0.694712   \n",
       "8                    0.779220                  0.711245   \n",
       "9                    0.774038                  0.760590   \n",
       "10                   0.773160                  0.729462   \n",
       "11                   0.770534                  0.771915   \n",
       "12                   0.768857                  0.722765   \n",
       "13                   0.765514                  0.742057   \n",
       "\n",
       "    rfr_baseline_sci_losses_train  rfr_baseline_sci_losses_test  \\\n",
       "0                        0.651928                      1.330899   \n",
       "1                        0.754838                      0.775406   \n",
       "2                        0.762508                      0.741030   \n",
       "3                        0.757696                      0.723586   \n",
       "4                        0.752931                      0.807932   \n",
       "5                        0.762991                      0.854253   \n",
       "6                        0.774764                      0.861464   \n",
       "7                        0.778617                      0.675934   \n",
       "8                        0.770295                      0.722962   \n",
       "9                        0.765941                      0.758032   \n",
       "10                       0.765970                      0.723871   \n",
       "11                       0.763163                      0.750645   \n",
       "12                       0.760381                      0.706813   \n",
       "13                       0.756869                      0.728658   \n",
       "\n",
       "    xgb_baseline_losses_train  xgb_baseline_losses_test  \\\n",
       "0                    0.298636                  1.701912   \n",
       "1                    0.440828                  0.983207   \n",
       "2                    0.507057                  0.830562   \n",
       "3                    0.540714                  0.737487   \n",
       "4                    0.562597                  0.817999   \n",
       "5                    0.592883                  0.881255   \n",
       "6                    0.616987                  0.893641   \n",
       "7                    0.622944                  0.810184   \n",
       "8                    0.627419                  0.827886   \n",
       "9                    0.627335                  0.767380   \n",
       "10                   0.633010                  0.718728   \n",
       "11                   0.637305                  0.760866   \n",
       "12                   0.640751                  0.697524   \n",
       "13                   0.638602                  0.677788   \n",
       "\n",
       "    xgb_baseline_sci_losses_train  xgb_baseline_sci_losses_test  \\\n",
       "0                        0.264178                      1.620042   \n",
       "1                        0.404515                      0.961906   \n",
       "2                        0.477784                      0.775607   \n",
       "3                        0.513552                      0.715478   \n",
       "4                        0.536566                      0.799842   \n",
       "5                        0.566314                      0.869327   \n",
       "6                        0.591017                      0.922350   \n",
       "7                        0.599696                      0.829277   \n",
       "8                        0.604393                      0.806893   \n",
       "9                        0.606709                      0.760211   \n",
       "10                       0.612339                      0.708564   \n",
       "11                       0.616239                      0.728712   \n",
       "12                       0.620622                      0.694678   \n",
       "13                       0.621636                      0.687273   \n",
       "\n",
       "    rfr_baseline_lex_google_losses_train  rfr_baseline_lex_google_losses_test  \\\n",
       "0                               0.548788                             1.220528   \n",
       "1                               0.662272                             0.865908   \n",
       "2                               0.666381                             0.829693   \n",
       "3                               0.657579                             0.764084   \n",
       "4                               0.653659                             0.831459   \n",
       "5                               0.663504                             0.843810   \n",
       "6                               0.669174                             0.821221   \n",
       "7                               0.664334                             0.709299   \n",
       "8                               0.650919                             0.719212   \n",
       "9                               0.637234                             0.769444   \n",
       "10                              0.626943                             0.733662   \n",
       "11                              0.619546                             0.760020   \n",
       "12                              0.613457                             0.717703   \n",
       "13                              0.608019                             0.732488   \n",
       "\n",
       "    rfr_baseline_lex_google_sci_losses_train  \\\n",
       "0                                   0.543343   \n",
       "1                                   0.662111   \n",
       "2                                   0.665967   \n",
       "3                                   0.657157   \n",
       "4                                   0.653390   \n",
       "5                                   0.663394   \n",
       "6                                   0.668374   \n",
       "7                                   0.663530   \n",
       "8                                   0.650074   \n",
       "9                                   0.637021   \n",
       "10                                  0.626888   \n",
       "11                                  0.619527   \n",
       "12                                  0.613438   \n",
       "13                                  0.608014   \n",
       "\n",
       "    rfr_baseline_lex_google_sci_losses_test  \\\n",
       "0                                  1.326225   \n",
       "1                                  0.849453   \n",
       "2                                  0.805936   \n",
       "3                                  0.756091   \n",
       "4                                  0.823574   \n",
       "5                                  0.845505   \n",
       "6                                  0.820134   \n",
       "7                                  0.698256   \n",
       "8                                  0.735772   \n",
       "9                                  0.770078   \n",
       "10                                 0.733561   \n",
       "11                                 0.759843   \n",
       "12                                 0.716925   \n",
       "13                                 0.732266   \n",
       "\n",
       "    xgb_baseline_lex_google_losses_train  xgb_baseline_lex_google_losses_test  \\\n",
       "0                               0.124243                             1.158518   \n",
       "1                               0.249522                             1.121128   \n",
       "2                               0.328833                             1.025142   \n",
       "3                               0.370802                             0.958089   \n",
       "4                               0.398549                             0.929068   \n",
       "5                               0.427720                             0.877050   \n",
       "6                               0.438885                             0.903794   \n",
       "7                               0.442985                             0.837649   \n",
       "8                               0.445284                             1.025254   \n",
       "9                               0.443288                             0.870846   \n",
       "10                              0.445028                             1.006565   \n",
       "11                              0.447270                             1.016009   \n",
       "12                              0.451881                             1.007809   \n",
       "13                              0.450587                             0.971356   \n",
       "\n",
       "    xgb_baseline_lex_google_sci_losses_train  \\\n",
       "0                                   0.106177   \n",
       "1                                   0.237589   \n",
       "2                                   0.310682   \n",
       "3                                   0.363219   \n",
       "4                                   0.385329   \n",
       "5                                   0.417948   \n",
       "6                                   0.430292   \n",
       "7                                   0.435387   \n",
       "8                                   0.439898   \n",
       "9                                   0.439217   \n",
       "10                                  0.438914   \n",
       "11                                  0.442675   \n",
       "12                                  0.444940   \n",
       "13                                  0.444691   \n",
       "\n",
       "    xgb_baseline_lex_google_sci_losses_test  \n",
       "0                                  1.282564  \n",
       "1                                  1.207949  \n",
       "2                                  1.156474  \n",
       "3                                  1.172175  \n",
       "4                                  0.932373  \n",
       "5                                  0.859528  \n",
       "6                                  0.822174  \n",
       "7                                  0.851547  \n",
       "8                                  1.039725  \n",
       "9                                  0.867469  \n",
       "10                                 0.832521  \n",
       "11                                 0.993953  \n",
       "12                                 0.796302  \n",
       "13                                 1.031364  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replication_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension - XGBoost model on all available data (lagged values and controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select lagged variables\n",
    "cols_extended = []\n",
    "cols_sci = []\n",
    "for colname in ts_df.columns:\n",
    "    if 'l1' in colname or 'l2' in colname:\n",
    "        if 'swc' in colname or 'swd' in colname:\n",
    "            cols_sci.append(colname)\n",
    "        else:\n",
    "            cols_extended.append(colname)\n",
    "# add fixed control variables\n",
    "cols_extended += ['med_hhinc2016_10k', \n",
    "                  'popdensity2010_10k',  \n",
    "                  'share_within50', \n",
    "                  'share_within150']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1_pchg_gogl_fever',\n",
       " 'l1_pchg_gogl_cough',\n",
       " 'l1_pchg_gogl_fatigue',\n",
       " 'l1_chg_dwc_10k',\n",
       " 'l2_chg_dwc_10k',\n",
       " 'l1_chg_lwc_10k',\n",
       " 'l2_chg_lwc_10k',\n",
       " 'l1_chg_cases_10k',\n",
       " 'l2_chg_cases_10k',\n",
       " 'l2_chg_dwd_10k_4wk',\n",
       " 'l2_chg_lwd_10k_4wk',\n",
       " 'l2_chg_deaths_10k_4wk',\n",
       " 'log_l1_chg_cases_10k',\n",
       " 'log_l2_chg_cases_10k',\n",
       " 'log_l1_chg_dwc_10k',\n",
       " 'log_l2_chg_dwc_10k',\n",
       " 'log_l1_chg_lwc_10k',\n",
       " 'log_l2_chg_lwc_10k',\n",
       " 'log_l2_chg_deaths_10k_4wk',\n",
       " 'log_l2_chg_dwd_10k_4wk',\n",
       " 'log_l2_chg_lwd_10k_4wk',\n",
       " 'med_hhinc2016_10k',\n",
       " 'popdensity2010_10k',\n",
       " 'share_within50',\n",
       " 'share_within150']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list af all features used\n",
    "cols_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1_chg_swc_10k',\n",
       " 'l2_chg_swc_10k',\n",
       " 'l2_chg_swd_10k_4wk',\n",
       " 'log_l1_chg_swc_10k',\n",
       " 'log_l2_chg_swc_10k',\n",
       " 'log_l2_chg_swd_10k_4wk']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of SCI features\n",
    "cols_sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supplementary data management function\n",
    "def get_train_test_data(train, test, colnames):\n",
    "    x_train = train[colnames + target]\n",
    "    x_train = x_train.dropna()\n",
    "    y_train = x_train[target]\n",
    "    x_train = x_train.drop(target, axis=1)\n",
    "    x_test = test[colnames].fillna(0)\n",
    "    y_test = test[target]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0105826a68bb48069384cd8d5f140251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline train DF shape : (1976, 25)\n",
      "Baseline+SCI train DF shape : (1976, 31)\n",
      "0.5484403649033528 1.2167818591475341\n",
      "\n",
      "Baseline train DF shape : (3952, 25)\n",
      "Baseline+SCI train DF shape : (3952, 31)\n",
      "0.6620685446377401 0.860951561381698\n",
      "\n",
      "Baseline train DF shape : (5928, 25)\n",
      "Baseline+SCI train DF shape : (5928, 31)\n",
      "0.66631924571268 0.82664139735479\n",
      "\n",
      "Baseline train DF shape : (7904, 25)\n",
      "Baseline+SCI train DF shape : (7904, 31)\n",
      "0.656830871300273 0.7640903356626092\n",
      "\n",
      "Baseline train DF shape : (9880, 25)\n",
      "Baseline+SCI train DF shape : (9880, 31)\n",
      "0.6538564967679518 0.8304067813249559\n",
      "\n",
      "Baseline train DF shape : (11856, 25)\n",
      "Baseline+SCI train DF shape : (11856, 31)\n",
      "0.6628300899343122 0.8433000393859917\n",
      "\n",
      "Baseline train DF shape : (13832, 25)\n",
      "Baseline+SCI train DF shape : (13832, 31)\n",
      "0.6691598731657895 0.8209147296152023\n",
      "\n",
      "Baseline train DF shape : (15808, 25)\n",
      "Baseline+SCI train DF shape : (15808, 31)\n",
      "0.6644410586553855 0.7081537022378744\n",
      "\n",
      "Baseline train DF shape : (17784, 25)\n",
      "Baseline+SCI train DF shape : (17784, 31)\n",
      "0.650912543901794 0.7195477204341356\n",
      "\n",
      "Baseline train DF shape : (19760, 25)\n",
      "Baseline+SCI train DF shape : (19760, 31)\n",
      "0.6378411553241027 0.7706699349811704\n",
      "\n",
      "Baseline train DF shape : (21736, 25)\n",
      "Baseline+SCI train DF shape : (21736, 31)\n",
      "0.6268562651138074 0.7332690463807454\n",
      "\n",
      "Baseline train DF shape : (23712, 25)\n",
      "Baseline+SCI train DF shape : (23712, 31)\n",
      "0.6194771620233698 0.7599502006223009\n",
      "\n",
      "Baseline train DF shape : (25688, 25)\n",
      "Baseline+SCI train DF shape : (25688, 31)\n",
      "0.6138500531616149 0.717605755350081\n",
      "\n",
      "Baseline train DF shape : (27664, 25)\n",
      "Baseline+SCI train DF shape : (27664, 31)\n",
      "0.6081437807997624 0.7329738991324775\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iterative out-of-sample prediction\n",
    "ext_losses = []\n",
    "ext_sci_losses = []\n",
    "\n",
    "for week_num in tqdm(range(17, 45, 2)):\n",
    "    train = ts_df.loc[ts_df['week_num'] < week_num]\n",
    "    test = ts_df.loc[ts_df['week_num'] == week_num]\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = get_train_test_data(train, test, cols_extended)\n",
    "    print(f'Baseline train DF shape : {x_train.shape}')\n",
    "    \n",
    "    x_train_sci, y_train_sci, x_test_sci, y_test_sci = get_train_test_data(train, test, cols_extended + cols_sci)\n",
    "    print(f'Baseline+SCI train DF shape : {x_train_sci.shape}')\n",
    "    \n",
    "    # xgboost without SCI\n",
    "    train_loss, test_loss = fit_random_forest(x_train=x_train, \n",
    "                                                y_train=y_train, \n",
    "                                                x_test=x_test, \n",
    "                                                y_test=y_test)\n",
    "    \n",
    "    ext_losses.append([train_loss, test_loss])\n",
    "        \n",
    "    # xgboost with SCI\n",
    "    xgb_train_loss, xgb_test_loss = fit_random_forest(x_train=x_train_sci, \n",
    "                                                y_train=y_train_sci, \n",
    "                                                x_test=x_test_sci, \n",
    "                                                y_test=y_test_sci)\n",
    "    \n",
    "    ext_sci_losses.append([xgb_train_loss, xgb_test_loss])\n",
    "    \n",
    "    print(train_loss, test_loss)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct and save resulting DataFrame with XGBoost RMSEs on train and test data\n",
    "ext_df = pd.DataFrame()\n",
    "\n",
    "ext_losses = np.array(ext_losses)\n",
    "ext_sci_losses = np.array(ext_sci_losses)\n",
    "\n",
    "ext_df['xgb_losses_train'] = ext_losses[:, 0]\n",
    "ext_df['xgb_losses_test'] = ext_losses[:, 1]\n",
    "\n",
    "ext_df['xgb_sci_losses_train'] = ext_sci_losses[:, 0]\n",
    "ext_df['xgb_sci_losses_test'] = ext_sci_losses[:, 1]\n",
    "\n",
    "ext_df.to_csv('ext_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
